# TODO: To-Be-Named

## Computer Vision

Computer vision refers to understanding images/videos, usually using ML/AI. There are many tasks of interest:
  
- Image classification: Cat vs. Dog?
- Object localization: Where are the people in this image?
- Image segmentation: What are the various parts of this image?
- Motion Detection: What moved between frames of a video?
- Etc.

### Feature importances for computer vision

- LIME can be used to shade the image based on importance
- It takes longer to render the explanation than it does the prediction.

### Neural Networks (Neural Net)

A neural network is a model similar to a pipeline. It involves a series of transformations ("layers") internally and the output is the prediction. Deep learning is using neural networks.

_**Advantages:**_

- Can learn very complex functions
  - The fundamental tradeoff is primarily controlled by the number of layers and layer sizes.
  - More layers / bigger layers -> more complex model.
  - You can generally get a model that will not underfit.
- Works really well for structured data
  - 1D sequence, e.g. timeseries, language
  - 2D image
  - 3D image or video
- Incredible successes in the last 10 years
- Transfer learning is really useful

_**Disadvantages:**_

- Often requires a lot of data
- Require a lot of compute time, and, to be faster, specialized hardware called GPUs
- Huge numbers of hyperparameters are a huge pain to tune; also slow
- Not interpretable
- Calling `fit` does not guarantee optimality
  - There are now a bunch of hyperparameters specific to fit, rather than the model.
  - You never really know if fit was successful or not.
  - You never really know if you should have run fit for longer.
- Not recommended training neural nets without further training

#### Neural Networks for Images

Two ways of processing images is:

- Flattening images (Naive)
  - Throws away a lot of useful information; computer only sees an array of numbers
- Convolutional neural networks: Can take in images without flattening them

#### Using Pre-Trained Networks

`tf.keras` has a bunch of pre-trained computer vision models. Using a dataset, we can get predictions without "doing ML ourselves". This can be useful for sentiment analysis.

_**Advantages:**_

- Saves time/cost/effort/resources
- Can use pre-trained networks directly or use them as feature transformers

#### Transfer Learning

Transfer learning is using a model trained on one task as a starting point for learning to perform another task. This is useful because it is difficult to obtain labelled data.

- Requires setting things up the same way they were set up when the model was trained (e.g., image size)

## Communication

### TODO L20-21

## [Ethics](https://github.com/UBC-CS/cpsc330/blob/master/lectures/22_ethics.ipynb)

Problems include ethics, bias, fairness, AI safety, privacy, etc.

### Bias

A model's confidence should not equate to your confidence.

_**How could this sort of bias affect peoples' lives negatively?**_
Many ways that it could affect us but unsure what exactly. Some things include advertisements, admissions, etc.

_**Where does bias come from?**_

- Data (if data only has certain groups in certain situations)
- Labels (if they were generated by humans, or not)
- Learning method (this is harder to get at)
- Bias in the way ML method is used/deployed.

### AI saftey and adversarial examples

_**Is it safe to use ML?**_
Not necessarily. An attacker can introduce noise to an image (software attack) or add a sticker with confusing material (physical attack) which can lead to a wrong prediction. With this fragility, we need to consider the application of this technology (e.g., self-driving cars). For instance, what happens if a car cannot detect a stop sign because of the sticker and runs into a person. It's not a question of do they work but rather can someone mess it up.

### Fake news and deepfakes

Fake pictures and videos and the inability to tell if it is real.

### Environmental impact

Current methods require a lot of data, time to train, many training runs to do hyperparameter optimization, resulting in a lot of energy emissions. Is this ethical?

### Crime machine learning

Predicting whether someone is a criminal based on their face

- Your prediction algorithm is only as good (or bad) as your training data
- Sources of bias:
  - Wearing a white shirt and jacket vs. other clothes
  - Facial expressions (smiling vs. frowning)
  - Cropping, lighting
  - Biased criminal justice system (e.g., tends to convict less attractive faces)
  - How can our algorithm be "better" (less biased) than humans if humans labeled the data?

### Avoiding bias in experimental set-up

- Are my results too good to be true?
- Use baselines like DummyClassifier and DummyRegressor.
- Look at feature importances.
- Manually look at some of the correct/incorrect predictions (or very low/high error for regression).
- Try making changes or perturbations (e.g. different train/validation folds) and check if your results are robust.
- When you are done, think carefully about your confidence (or credence, see lecture 21) regarding any claims you make.

### Avoiding ethical/fairness issues

- Bias usually comes from the data, not the algorithm. Think carefully about how the training data were collected.
- Familiarize yourself with how your model will be used.
- Ask yourself who might be affected by this model in deployment
